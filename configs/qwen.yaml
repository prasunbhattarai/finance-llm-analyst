model:
  model_name: "Qwen/Qwen2.5-3B-Instruct"
  cache_dir: "models/base_model"
  quantization:
    load_in_4bit: True
    bnb_4bit_compute_dtype: "float16"
    bnb_4bit_quant_type: "nf4"

lora:
  r: 8
  lora_alpha: 16
  lora_dropout: 0.05
  bias: "none"
  target_modules: ["q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj","down_proj"]

training:
  num_train_epochs: 4
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 2
  learning_rate: 2e-5
  fp16: True
  lr_scheduler_type: "cosine"
  eval_steps: 100
  logging_steps: 50
  logging_dir: "./logs"
  save_strategy: "epoch"
  remove_unused_columns: False
  label_names: ['labels']
  eval_strategy: 'steps'
  
data:
  dolly_dir: "datasets/raw/dolly"
  fiqa_dir: "datasets/raw/fiqa"
  synthetic_dir: "dataset/synthetic_dataset/dataset.json"
  train_data: "datasets/train"
  test_data: "datasets/test"
  
output:
  dir: "models/fined_tuned"
  hf_repo: "prasun77/qwen-finance-lora"


# For RAG

Stocks:
  stocks_dataset: "dataset/stocks_dataset/stocks_data.csv"

Chroma:
  persist_dir: "chroma_db"